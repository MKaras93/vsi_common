#!/usr/bin/env false
# Source this file

: ${VSI_COMMON_DIR="$(dirname "${BASH_SOURCE[0]}")/.."}
source "${VSI_COMMON_DIR}/linux/isin"

#****F* vsi/cuda_info.bsh
# NAME
#   cuda_info.bsh - Determine easy to use capabilities for CUDA devices
# DESCRIPTION
#   There are many versions of CUDA, CUDA card architectures, etc... Knowing
#   how to compile for a specific card is hard enough, but it's very difficult
#   to know what the right architectures are for your specific card and what
#   the limitations are based on your version of CUDA/NVIDIA driver, etc.
#   This script should help determine what versions you have and suggest what
#   architectures to use. This is good enough for an automated "fire and
#   forget" getting started and running solution. But these answers are not
#   absolute. There are always fine tuning solution you may find that work
#   better on a case by case situation.
# AUTHOR
#   Andy Neff
#***

#****d* cuda_info.bsh/CUDA_VERSION
# NAME
#   CUDA_VERSION - The version of CUDA being used
# DESCRIPTION
#   cuda_info.bsh will attempt to discover the CUDA Development Kit in commonly
#   known locations, and accumulate a list of all discovered CDKs in the sorted
#   array CUDA_VERSIONS. Then the highest capable version of CUDA is picked and
#   set to CUDA_VERSION.
#
#   CUDA_VERSION can optionally be set to a specific version (e.g. "7.5.13"),
#   in which case other cuda versions will not be discovered and CUDA_VERSIONS
#   will not be populated.
# NOTES
#   Currently, CDKs are discovered by checking the system PATH and
#   /usr/local/cuda*/bin/ directories for the nvcc command. More paths should
#   be added to this file as they become necessary.
# AUTHOR
#   Andy Neff
#***

#****fi* cuda_info.bsh/discover_cuda_versions
# NAME
#   discover_cuda_versions - Find CUDA development kits
# OUTPUT
#   CUDA_VERSIONS - List of CUDA versions found
# AUTHOR
#   Andy Neff
#***
function discover_cuda_versions()
{
  CUDA_VERSIONS=()
  local IFS=$'\n' #Handle spaces, tabs, but not newlines in the paths
  local version
  for version in $(command -v nvcc) /usr/local/cuda*/bin/nvcc; do
    CUDA_VERSIONS+=($("${version}" --version | \awk 'END{print substr($6, 2)}'))
  done 2>/dev/null

  # This will sort correctly technically until CUDA 10 comes out. And even
  # Then, no one used cuda 1, so it is good enough
  CUDA_VERSIONS=($(sort -u <<< ${CUDA_VERSIONS+"${CUDA_VERSIONS[*]}"}))
  # Get the highest cuda level
  CUDA_VERSION=${CUDA_VERSIONS+"${CUDA_VERSIONS[${#CUDA_VERSIONS[@]}-1]}"}
}

#****d* cuda_info.bsh/CUDA_DISCOVER
# NAME
#   CUDA_DISCOVER - Flag to enable the discovery of CUDA cards and capabilities
# INPUTS
#   CUDA_DISCOVER - Default is disabled, set to "1" to enable.
# DESCRIPTION
#   Since the CUDA card discovery can be expensive (milliseconds on some
#   computers, hundreds on other computers) it is disabled by default, so that
#   it must be explicitly enabled on purpose.
#
#   There are two methods for CUDA device discovery:
#   1. Using deviceQuery (available here https://goo.gl/ocBgPU)
#   2. Using the nvidia-docker-plugin to get and parse GPU information
#
#   If deviceQuery is found (Looks for ${DEVICE_QUERY-deviceQuery} on the PATH)
#   then it is used, else if nvidia-docker-plugin can be discovered (using
#   NV_HOST or checking to see if nvidia-docker-plugin is running locally using
#   pgrep or ps)
#
#   When running in a docker, deviceQuery is the preferred method. NV_HOST
#   could be used, but that involves telling the docker the IP of the host, or
#   using a shared network mode in order to use localhost (which is not
#   recommended for production). Attempting to discover nvidia-docker-plugin
#   will not work in a docker.
# AUTHOR
#   Andy Neff
#***

#****d* cuda_info.bsh/CUDA_CARDS
# NAME
#   CUDA_CARDS - List of CUDA devices found on the computer
# DESCRIPTION
#   An array of all the CUDA cards discovered. The only way to manually override
#   this would be to disable CUDA_DISCOVER, but that was not the intended use.
# AUTHOR
#   Andy Neff
#***

#****d* cuda_info.bsh/CUDA_CARD_ARCHES
# NAME
#   CUDA_CARD_ARCHES - List of CUDA card architectures
# DESCRIPTION
#   An array of all the architectures the CUDA cards discovered. The only way
#   to manually override this would be to disable CUDA_DISCOVER, but that was
#   not the intended use.
# AUTHOR
#   Andy Neff
#***


#****d* cuda_info.bsh/CUDA_CARD_FAMILIES
# NAME
#   CUDA_CARD_FAMILIES - List of CUDA card family names.
# DESCRIPTION
#   An array of all the family names of the CUDA cards discovered. The only way
#   to manually override this would be to disable CUDA_DISCOVER, but that was
#   not the intended use.
# NOTES
#   If deviceQuery is not used, then an internal lookup table is used, but only
#   supports Tesla, Fermi, Kepler, Maxwell, Pascal, and Volta. Additional family
#   names need to be added as they are released.
# AUTHOR
#   Andy Neff
#***

#****fi* cuda_info.bsh/discover_cuda_info
# NAME
#   discover_cuda_info - Get CUDA info about each card
# OUTPUT
#   CUDA_CARDS - List of all CUDA capable devices
#   CUDA_CARD_ARCHES - Matching list of CUDA real architectures
#   CUDA_CARD_FAMILIES - Matching list of CUDA families
# AUTHOR
#   Andy Neff
#***
function discover_cuda_info()
{
  if command -v pgrep &>/dev/null; then
    function nvidia_docker_is_running()
    {
      \pgrep -f "${1}" &> /dev/null
      return $?
    }
  else
    function nvidia_docker_is_running()
    {
      [ $(\ps -ef | \grep "${1}" | \wc -l) -gt 1 ]
      return $?
    }
  fi

  #****d* cuda_info.bsh/DEVICE_QUERY
  # NAME
  #   DEVICE_QUERY - Name of the device query executable
  # USAGE
  #   Optional override for the name of the executable for device query. Device
  #   query is one of the sample programs in the CUDA Development Kit that prints
  #   out useful information about the connected CUDA devices.
  #
  #   DEVICE_QUERY defaults to "deviceQuery", and search the system path for a
  #   matching executable name. Can also be a absolute path.
  #
  #   The deviceQuery executable is compiled from the source code typically
  #   found the in /usr/local/cuda/samples/1_Utilities/deviceQuery/ directory,
  #   but can be downloaded precompiled for Linux from https://goo.gl/equvX3
  # AUTHOR
  #   Andy Neff
  #***

  local IFS="${IFS}"
  local OLD_IFS="${IFS}"

  # Attempt to use deviceQuery
  if command -v "${DEVICE_QUERY-deviceQuery}" &> /dev/null; then
    local card_info cuda_card_arches cuda_card_families
    local x y

    card_info="$(${DEVICE_QUERY-deviceQuery} | \grep -E "CUDA Capability Major/Minor version number|^Device")"
    CUDA_CARD_ARCHES=($(echo "${card_info}" | \grep "CUDA Capability Major/Minor version number" | \awk '{print $NF}'))
    IFS=$'\n'
    CUDA_CARDS=($(echo "${card_info}" | \grep ^Device | \awk '{$1=$2=""; $0=$0; $1=$1}1' | \sed 's|"||g'))
    IFS="${OLD_IFS}"
    CUDA_CARD_FAMILIES=()
    cuda_card_arches=(1 2 3 5 6 7) # Major version
    cuda_card_families=(Tesla Fermi Kepler Maxwell Pascal Volta) #Family name
    for x in ${CUDA_CARD_ARCHES+"${CUDA_CARD_ARCHES[@]}"}; do
      for y in "${!cuda_card_arches[@]}"; do
        if [ "${x:0:1}" == "${cuda_card_arches[$y]}" ]; then
          CUDA_CARD_FAMILIES+=("${cuda_card_families[$y]}")
          continue 2
        fi
      done
      CUDA_CARD_FAMILIES+=("Family Unknown")
    done
  #Else attempt to use nvidia-docker
  elif nvidia_docker_is_running nvidia-docker-plugin || declare -p NV_HOST &>/dev/null; then
    local download_cmd
    local card_info
    # Warning not in cuda order. Oh well
    if command -v curl &>/dev/null; then
      download_cmd="curl -s"
    else
      download_cmd="wget -qO-"
    fi

    card_info="$($download_cmd ${NV_HOST-http://localhost:3476}/gpu/info)"

    CUDA_CARD_FAMILIES=($(echo "${card_info}" | \grep Family: | \awk '{print $NF}'))
    CUDA_CARD_ARCHES=($(echo "${card_info}" | \grep Arch: | \awk '{print $NF}'))
    IFS=$'\n'
    CUDA_CARDS=($(echo "${card_info}" | \grep Model: | \awk '{$1=""; $0=$0; $1=$1}1'))
    IFS="${OLD_IFS}"
  else
    echo "deviceQuery not found and nvidia-docker plugin not running"
    echo "deviceQuery can be downloaded from https://vsi-ri.com/bin/deviceQuery60"
    echo "or https://goo.gl/equvX3"
  fi
  CUDA_CARD_ARCHES=(${CUDA_CARD_ARCHES+"${CUDA_CARD_ARCHES[@]/./}"})
}

#****d* cuda_info.bsh/CUDA_ARCHES
# NAME
#   CUDA_ARCHES - List of CUDA "virtual" instruction sets supported by CUDA
# DESCRIPTION
#   Every version of CUDA has a set of "virtual" compute_xx architectures that
#   it can compile for. This array contains a list of every compute
#   architecture supported for the version of CUDA specifies by CUDA_VERSION as
#   an array of two digit number.
#
#   When creating PTX CUDA binaries, there is no "real" instruction
#   architecture, and the "virtual" architecture compute_xx name is used again
#   in the code argument and the PTX code is JIT compiled at runtime.
# EXAMPLE
#   Adding the periods to the architecture version number:
#
#   y=()
#   for x in ${CUDA_ARCHES+"${CUDA_ARCHES[@]}"}; do
#     y+=("${x:0:${#x}-1}.${x:${#x}-1:1}")
#   done
# SEE ALSO
#   cuda_info.bsh/CUDA_DEPRECATED
# AUTHOR
#   Andy Neff
#***

#****d* cuda_info.bsh/CUDA_CODES
# NAME
#   CUDA_CODES - List of CUDA "real" instruction sets supported by CUDA
# DESCRIPTION
#   Every version of CUDA has a set of "real" sm_xx architectures that it can
#   compile for. This array contains a list of every sm architecture supported
#   for the version of CUDA specifies by CUDA_VERSION as an array of two digit
#   number.
#
#   When creating PTX CUDA binaries, there is no "real" instruction
#   architecture  used.
# SEE ALSO
#   cuda_info.bsh/CUDA_DEPRECATED
# AUTHOR
#   Andy Neff
#***

#****d* cuda_info.bsh/CUDA_MINIMAL_DRIVER_VERSION
# NAME
#   CUDA_MINIMAL_DRIVER_VERSION - Required version of NVIDIA driver
# DESCRIPTION
#   Every version of CUDA has a minimal version of the NVIDIA video card driver
#   that must be installed in order to support that version of CUDA. While this
#   is largely undocumented (despite being obviously important), this variable
#   is set to the minimal required version of the NVIDIA driver for the CUDA
#   version stored in CUDA_VERSION, as best as we've been able to determine.
# AUTHOR
#   Andy Neff
#***

#****d* cuda_info.bsh/CUDA_DEPRECATED
# NAME
#   CUDA_DEPRECATED - List of deprecated instruction sets supported by CUDA
# DESCRIPTION
#   Some versions of CUDA support old instruction sets, but print a deprecated
#   warning. For those versions of CUDA, a CUDA_DEPRECATED array is defined to
#   list the two digit architectures that are supported yet deprecated in the
#   CUDA_VERSION version of CUDA.
# AUTHOR
#   Andy Neff
#***


#****fi* cuda_info.bsh/cuda_capabilities
# NAME
#   cuda_capabilities - Determine compiler capabilities for specific CDK
# OUTPUT
#   CUDA_ARCHES - CUDA virtual architectures supported (compute_xx)
#   CUDA_CODES - CUDA real architectures supported (sm_xx)
#   CUDA_MINIMAL_DRIVER_VERSION - Minimal NVIDIA driver version needed for
#                                 CUDA_VERSION version of video card driver
#   [CUDA_DEPRECATED] - List of deprecated (yet working) architectures.
# AUTHOR
#   Andy Neff
#***

function cuda_capabilities()
{
  # This is the most complete list of compute and sm architectures supported by
  # CUDA version that I know of. It was created using strings on nvcc from each
  # version of CUDA. Documentation, stackoverflow, and random blogs often miss
  # at least one piece of information and is not this complete nor will it
  # verify this table.
  case ${CUDA_VERSION} in
    1.0*)
      CUDA_ARCHES=(10 11)
      CUDA_CODES=(10 11)
      if [ "${OS-}" == "Windows_NT" ]; then
        CUDA_MINIMAL_DRIVER_VERSION=162.01 #~
      else
        CUDA_MINIMAL_DRIVER_VERSION=100.14 #~
      fi
      ;;
    1.1*)
      CUDA_ARCHES=(10 11)
      CUDA_CODES=(10 11)
      CUDA_MINIMAL_DRIVER_VERSION=169.01
      ;;
    2.0*)
      CUDA_ARCHES=(10 11 12 13)
      CUDA_CODES=(10 11 12 13)
      CUDA_MINIMAL_DRIVER_VERSION=177.70 #~
      ;;
    2.1*)
      CUDA_ARCHES=(10 11 12 13)
      CUDA_CODES=(10 11 12 13)
      CUDA_MINIMAL_DRIVER_VERSION=180.22 #~
      ;;
    2.2*)
      CUDA_ARCHES=(10 11 12 13)
      CUDA_CODES=(10 11 12 13)
      CUDA_MINIMAL_DRIVER_VERSION=185.18.14 #~
      ;;
    2.3*)
      CUDA_ARCHES=(10 11 12 13)
      CUDA_CODES=(10 11 12 13)
      CUDA_MINIMAL_DRIVER_VERSION=190.53 #~
      ;;
    3.0*)
      CUDA_ARCHES=(10 11 12 13 20)
      CUDA_CODES=(10 11 12 13 20)
      CUDA_MINIMAL_DRIVER_VERSION=195.36.15
      ;;
    3.1*)
      CUDA_ARCHES=(10 11 12 13 20 30)
      CUDA_CODES=(10 11 12 13 20 21 22 23 30)
      CUDA_MINIMAL_DRIVER_VERSION=256.40
      ;;
    3.2*) #.16
      CUDA_ARCHES=(10 11 12 13 20)
      CUDA_CODES=(10 11 12 13 20 21)
      CUDA_MINIMAL_DRIVER_VERSION=260.19.26
      ;;
    4.0*) #.17
      CUDA_ARCHES=(10 11 12 13 20)
      CUDA_CODES=(10 11 12 13 20 21 22 23)
      CUDA_MINIMAL_DRIVER_VERSION=270.41.19
      ;;
    4.1*) #.28
      CUDA_ARCHES=(10 11 12 13 20)
      CUDA_CODES=(10 11 12 13 20 21)
      CUDA_MINIMAL_DRIVER_VERSION=285.05.33
      ;;
    4.2*) #.9
      CUDA_ARCHES=(10 11 12 13 20 30)
      CUDA_CODES=(10 11 12 13 20 21 30)
      CUDA_MINIMAL_DRIVER_VERSION=295.41
      ;;
    5.0*) #.35
      CUDA_ARCHES=(10 11 12 13 20 30 35)
      CUDA_CODES=(10 11 12 13 20 21 30 35)
      CUDA_MINIMAL_DRIVER_VERSION=304
      ;;
    5.5*) #.22
      CUDA_ARCHES=(10 11 12 13 20 30 35)
      CUDA_CODES=(10 11 12 13 20 21 30 35)
      CUDA_MINIMAL_DRIVER_VERSION=319
      ;;
    6.0*) #.1
      CUDA_ARCHES=(10 11 12 13 20 30 32 35 50)
      CUDA_CODES=(10 11 12 13 20 21 30 32 35 50)
      CUDA_MINIMAL_DRIVER_VERSION=331
      CUDA_DEPRECATED=(10)
      ;;
    6.5*) #.12
      CUDA_ARCHES=(11 12 13 20 30 32 35 37 50 52)
      CUDA_CODES=(11 12 13 20 21 30 32 35 37 50 52)
      CUDA_MINIMAL_DRIVER_VERSION=340
      CUDA_DEPRECATED=(11 12 13)
      ;;
    7.0*) #.27
      CUDA_ARCHES=(20 30 32 35 37 50 52 53)
      CUDA_CODES=(20 21 30 32 35 37 50 52 53)
      CUDA_MINIMAL_DRIVER_VERSION=346
      ;;
    7.5*) #.17
      CUDA_ARCHES=(20 30 32 35 37 50 52 53)
      CUDA_CODES=(20 21 30 32 35 37 50 52 53)
      CUDA_MINIMAL_DRIVER_VERSION=352
      ;;
    8*) #.0.61
      CUDA_ARCHES=(20 30 32 35 37 50 52 53 60 61 62)
      CUDA_CODES=(20 21 30 32 35 37 50 52 53 60 61 62)
      CUDA_MINIMAL_DRIVER_VERSION=361
      CUDA_DEPRECATED=(20 21)
      ;;
    9*) #RC2 .103
      CUDA_ARCHES=(30 32 35 37 50 52 53 60 61 62 70)
      CUDA_CODES=(30 32 35 37 50 52 53 60 61 62 70)
      CUDA_MINIMAL_DRIVER_VERSION=384.59 #Just a guess
      ;;
    #10*)
    # run "strings nvcc | grep compute_" and "sm_" and you'll get a complete list
    *)
      CUDA_ARCHES=()
      CUDA_CODES=()
      ;;
  esac
}

#****d* cuda_info.bsh/CUDA_SUGGESTED_ARCHES
# NAME
#   CUDA_SUGGESTED_ARCHES - Suggested "virtual" architectures to compile for
# DESCRIPTION
#   Instead of compiling for every architecture that the CUDA_VERSION version
#   of CUDA support, CUDA_SUGGESTED_ARCHES is a filtered list between your
#   CUDA_CARD_ARCHES and CUDA_ARCHES so that you compile only for your card.
# AUTHOR
#   Andy Neff
#***

#****d* cuda_info.bsh/CUDA_SUGGESTED_CODES
# NAME
#   CUDA_SUGGESTED_CODES - Suggested "real" architectures to compile for
# DESCRIPTION
#   Instead of compiling for every architecture that the CUDA_VERSION version
#   of CUDA support, CUDA_SUGGESTED_CODES is a filtered list between your
#   CUDA_CARD_CODES and CUDA_CODES so that you compile only for your card.
# AUTHOR
#   Andy Neff
#***

#****d* cuda_info.bsh/CUDA_SUGGESTED_PTX
# NAME
#   CUDA_SUGGESTED_PTX - Suggested PTX architectures to compile for
# DESCRIPTION
#   Instead of always adding a PTX compile (where you tell nvcc to compile a
#   virtual architecture as both the virtual and real architectures) all the,
#   time, CUDA_SUGGESTED_PTX lists suggested architectures to PTX build if your
#   card is too new for the CUDA_VERSION version of CUDA.
# AUTHOR
#   Andy Neff
#***

#****d* cuda_info.bsh/CUDA_FORWARD_PTX
# NAME
#   CUDA_FORWARD_PTX - PTX arch for newer CUDA cards
# DESCRIPTION
#   In situations where you are making portable fatbins, you will compile for
#   every architecture. However, in order to future proof your fatbin for
#   architectures newer than your current version of CUDA supports, you will
#   need to compile to a pure virtual architecture using the PTX feature so
#   that the real architecture is Just In Time compiled.
#
#   CUDA_FORWARD_PTX identifies the fullest featured PTX architecture so that
#   you can choose to add this to your builds.
# AUTHOR
#   Andy Neff
#***

#****fi* cuda_info.bsh/suggested_architectures
# NAME
#   suggested_architectures - Calculate suggested architectures
# OUTPUT
#  CUDA_SUGGESTED_ARCHES - Suggested virtual architectures for your cards
#  CUDA_SUGGESTED_CODES - Suggested real architectures for your cards
#  CUDA_SUGGESTED_PTX - Suggested PTX for your cards
#  CUDA_FORWARD_PTX - Potential forward compatibility PTX to compile for cards
#                     newer than your current CUDA supports
# AUTHOR
#   Andy Neff
#***
function suggested_architectures()
{
  local x arch y
  local IFS="${IFS}"

  CUDA_SUGGESTED_ARCHES=()
  CUDA_SUGGESTED_CODES=()
  CUDA_SUGGESTED_PTX=()

  # Loop through all the car aches
  for arch in ${CUDA_CARD_ARCHES+"${CUDA_CARD_ARCHES[@]}"}; do
    for x in ${CUDA_ARCHES+"${!CUDA_ARCHES[@]}"}; do
      # If it's an exact match, add it!
      if [ "${CUDA_ARCHES[$x]}" == "${arch}" ]; then
        CUDA_SUGGESTED_ARCHES+=("${arch}")
        continue 2
      # If it's greater than, that means there is no exact match.
      # The last compute checked was the right answer. Use that.
      elif [ "${CUDA_ARCHES[$x]}" -gt "${arch}" ]; then
        # Verify the compute family matches, else you probably have a card that
        # is too old, like a Fermi???
        if [ "${x}" -gt "0" ]; then
          CUDA_SUGGESTED_ARCHES+=("${CUDA_ARCHES[$x-1]}")
        else
          : #: CUDA_SUGGESTED_ARCHES+=("TOOOLD")
        fi
        continue 2
      fi
    done

    # If you get here, either you have a newer arch of an already supported arch,
    # or you have a newer card than this version of cuda supports. Let's check
    # the first case first.
    if [ "${CUDA_ARCHES[$x]:0:1}" == "${arch:0:1}" ]; then
      CUDA_SUGGESTED_ARCHES+=("${CUDA_ARCHES[$x]}")
    else
      # If you get here, that means you have have a newer card than this version
      # of cuda supports. So the best answer is to PTX compile for it.
      CUDA_SUGGESTED_PTX+=("${CUDA_ARCHES[$x]}")
    fi
  done

  for arch in ${CUDA_CARD_ARCHES+"${CUDA_CARD_ARCHES[@]}"}; do
    for x in ${CUDA_CODES+"${!CUDA_CODES[@]}"}; do
      # If it's an exact match, add it!
      if [ "${CUDA_CODES[$x]}" == "${arch}" ]; then
        CUDA_SUGGESTED_CODES+=("${arch}")
        continue 2
      # If it's greater than, that means there is no exact match.
      # The last compute checked was the right answer. Use that.
      elif [ "${CUDA_CODES[$x]}" -gt "${arch}" ]; then
        # Verify the compute family matches, else you probably have a card that
        # is too old, like a Fermi???
        if [ "${x}" == "0" ]; then
          # Too old
          : #CUDA_SUGGESTED_CODES+=("TOOOLD")
        else # if [ "${CUDA_CODES[$x-1]:0:1}" == "${arch:0:1}" ]; This should always be true
          CUDA_SUGGESTED_CODES+=("${CUDA_CODES[$x-1]}")
        fi
        continue 2
      fi
    done

    # If you get here, either you have a newer arch of an already supported arch,
    # or you have a newer card than this version of cuda supports. Let's check
    # the first case first.
    if [ "${CUDA_CODES[$x]:0:1}" == "${arch:0:1}" ]; then
      CUDA_SUGGESTED_CODES+=("${CUDA_CODES[$x]}")
    else
      # If you get here, that means you have have a newer card than this version
      # of cuda supports. So the best answer is to PTX compile for it.
      CUDA_SUGGESTED_PTX+=("${CUDA_CODES[$x]}")
    fi
  done

  CUDA_FORWARD_PTX=${CUDA_ARCHES+"${CUDA_ARCHES[${#CUDA_ARCHES[@]}-1]}"}

  IFS=$'\n'
  CUDA_SUGGESTED_ARCHES=($(sort -u <<< ${CUDA_SUGGESTED_ARCHES+"${CUDA_SUGGESTED_ARCHES[*]}"}))
  CUDA_SUGGESTED_CODES=($(sort -u <<< ${CUDA_SUGGESTED_CODES+"${CUDA_SUGGESTED_CODES[*]}"}))
  CUDA_SUGGESTED_PTX=($(sort -u <<< ${CUDA_SUGGESTED_PTX+"${CUDA_SUGGESTED_PTX[*]}"}))
}

#****f* cuda_info.bsh/cmake_cuda_flags
# NAME
#   cmake_cuda_flags - Generate CUDA flags for cmake
# DESCRIPTION
#   Modern cmake installs include a FindCUDA.cmake file which calls the
#   select_compute_arch.cmake file (https://goo.gl/uZvAjR). This uses a limited
#   version of the tables that cuda_info.bsh use, and is prone to being out of
#   date.
#
#   This function will calculate the suggested value of
#   target_CUDA_architectures for CMake's:
#
#     FindCUDA.cmake:select_compute_arch.cmake:CUDA_SELECT_NVCC_ARCH_FLAGS
#
#   You will need to find where this is used and set the variable accordingly.
# INPUTS
#   CUDA_SUGGESTED_ARCHES - List of virtual architectures to compile
#   CUDA_SUGGESTED_CODES - Matching list of real architectures to compile
#   CUDA_SUGGESTED_PTX - Optional list of PTX architectures to compile
# OUTPUT
#   stdout - echoes out the value of the target_CUDA_architectures
# EXAMPLE
#   For example, PyTorch's cmake contains:
#     CUDA_SELECT_NVCC_ARCH_FLAGS(NVCC_FLAGS_EXTRA $ENV{TORCH_CUDA_ARCH_LIST})
#   Setting the environment variable TORCH_CUDA_ARCH_LIST to the output
#   of cmake_cuda_flags will result in using the desired CUDA architecture and
#   code versions.
#
#   To add the CUDA_FORWARD_PTX, run:
#     CUDA_SUGGESTED_PTX+=(${CUDA_FORWARD_PTX})
#   before calling cmake_cuda_flags
# AUTHOR
#   Andy Neff
#***
function cmake_cuda_flags()
{
  local cmake=()
  local x
  local y
  local ptx
  local OLD_IFS="${IFS}"

  for i in "${!CUDA_SUGGESTED_ARCHES[@]}"; do
    if [ "${CUDA_SUGGESTED_ARCHES[$i]}" == "${CUDA_SUGGESTED_CODES[$i]}" ]; then
      x="${CUDA_SUGGESTED_ARCHES[$i]}"
      x="${x:0:${#x}-1}.${x:${#x}-1:1}"
    else
      x="${CUDA_SUGGESTED_CODES[$i]}"
      y="${CUDA_SUGGESTED_ARCHES[$i]}"
      x="${x:0:${#x}-1}.${x:${#x}-1:1}"
      y="${y:0:${#y}-1}.${y:${#y}-1:1}"
      x="${x}(${y})"
    fi
    cmake+=($x)
  done

  ptx=(${CUDA_SUGGESTED_PTX+"${CUDA_SUGGESTED_PTX[@]}"})
  IFS=$'\n'
  ptx=($(echo "${ptx+"${ptx[*]}"}" | sort -u))
  IFS="${OLD_IFS}"
  for i in "${!ptx[@]}"; do
    x="${CUDA_SUGGESTED_PTX[$i]}"
    x="${x:0:${#x}-1}.${x:${#x}-1:1}"
    cmake+=("${x}+PTX")
  done

  echo -n ${cmake+"${cmake[*]}"}
}

# Call all of the CUDA discovery functions

if [ "${CUDA_VERSION+set}" != "set" ]; then
  discover_cuda_versions
fi

if [ "${CUDA_DISCOVER-}" == "1" ] && [ "${CUDA_VERSION+set}" == "set" ]; then
  discover_cuda_info
fi
#unset CUDA_DISCOVER ??? To prevent multiple calls

cuda_capabilities
suggested_architectures
